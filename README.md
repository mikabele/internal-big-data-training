# Internal Big Data Training repository

## Tasks
1. Task1 - Linux and Bash : there you can install docker containers with preinstalled environment for further tasks.
2. Task2 - Hadoop Cluster : 3-nodes cluster with configured services Hive and Spark
3. Task3 - SQL : Find average fund statistics using only MySQL
4. Task4 - Hive : The same task - find average fund statistics - but using only Hive and HPLSQL
5. Task5 - Spark : Find average fund statistics with Spark . Consists of 3 subtasks - RDD,Dataframe and SQL. Dataframe
and SQL have only Zeppelin realization. 
6. Task6 - Scala : The same task using pure Scala and Scala's Map/Reduce functionality
7. Task7 - Snowflake : The same as before but using Cloud DB Snowflake.
8. Task8 - CI/CD : Configured Jenkins pipeline using Jenkinsfile with small stage of testing and deploying JAR file into GCP's Compute 
Engine